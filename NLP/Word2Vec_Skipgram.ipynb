{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7YIp5hoH-5Of",
        "XnwjPBzW_vLX",
        "usP8Y3ApAe-2",
        "TJrucsI7AQnW"
      ],
      "authorship_tag": "ABX9TyPYOMB4fmo3xGqUfViAYD2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castlechoi/studyingDL/blob/main/NLP/Word2Vec_Skipgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "7YIp5hoH-5Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download corpus"
      ],
      "metadata": {
        "id": "uaXgv0fD_bIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.book에 저장된 corpus\n",
        "import nltk\n",
        "nltk.download(\"book\", quiet = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycnS7Vet_a0H",
        "outputId": "ad56df52-cc90-426a-e4c9-95c727355147"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Fn90_mmb-0zG"
      },
      "outputs": [],
      "source": [
        "# Load nltk.book.text1 \n",
        "from nltk.book import text1\n",
        "ex_book = nltk.book.text1[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop-words 제거"
      ],
      "metadata": {
        "id": "XnwjPBzW_vLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# stop-words에 특수기호 추가\n",
        "stopwords  = stopwords + ['.',',','\\'','!','?','\\\"','[',']','(',')','*','I',':',';','-','.\"','--','<','>']\n",
        "print(f'Stop-words의 개수 : {len(stopwords)}')\n",
        "\n",
        "ex_book_no_stopwords = [[t] for t in ex_book if t not in stopwords]\n",
        "print(f'불용어 제외한 후 문장의 길이 : {len(ex_book_no_stopwords)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9SoL673_xNo",
        "outputId": "e287bf21-1ef6-4618-e319-08b0e4ca186d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop-words의 개수 : 198\n",
            "불용어 제외한 후 문장의 길이 : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing hyperparameter"
      ],
      "metadata": {
        "id": "usP8Y3ApAe-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_count = 2\n",
        "window = 2"
      ],
      "metadata": {
        "id": "hmuepPfFAhx2"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Encoding"
      ],
      "metadata": {
        "id": "TJrucsI7AQnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NK6vCgZDATXu"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 집합 추출 ( 등장횟수가 2이하면 토큰화 안함)\n",
        "cut_off = 0\n",
        "\n",
        "tokens = pd.Series(ex_book_no_stopwords).value_counts()\n",
        "for i in range(len(tokens)):\n",
        "  if tokens[i] == min_count-1:\n",
        "    cut_off = i\n",
        "    break\n",
        "\n",
        "tokens = tokens[:cut_off].index.tolist()\n",
        "print(f'Token의 개수 : {len(tokens)}')\n",
        "\n",
        "\n",
        "# token에 없는 데이터 모두 '<unk>'로 변경\n",
        "ex_book_process = [t if t in tokens else ['<unk>'] for t in ex_book_no_stopwords]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7KV7AirAXTd",
        "outputId": "331469d4-0eb2-48c1-b5c9-e1a605ea0049"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token의 개수 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding\n",
        "oe = OneHotEncoder()\n",
        "document_matrix = oe.fit_transform(ex_book_process)\n",
        "print(f'문서의 단의 개수 : {document_matrix.shape[0]}')\n",
        "print(f'One-Hot vector의 크기 : {document_matrix.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL84tq4SA3c-",
        "outputId": "0c7fd67a-f23b-4def-facc-f6133cfa4793"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서의 단의 개수 : 50\n",
            "One-Hot vector의 크기 : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skipgram"
      ],
      "metadata": {
        "id": "wd-FQe8qA9_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "UJa47yWbCFR1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU 설정"
      ],
      "metadata": {
        "id": "ow_rZY1XA4St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 체크\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU is availalbe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eirIyl7A6Am",
        "outputId": "51abfd6a-9f3d-444a-a05c-2e41dfc40916"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train data preprocessing"
      ],
      "metadata": {
        "id": "Tk3hJ_SeBCyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# skipgram에 들어갈 input vector 1개\n",
        "#                   output vector 4개 ( window == 2)\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(document_matrix.shape[0] - (window * 2)):\n",
        "  neighbor = []\n",
        "  neighbor.append(document_matrix[i].toarray())\n",
        "  neighbor.append(document_matrix[i+1].toarray())\n",
        "  neighbor.append(document_matrix[i+3].toarray())\n",
        "  neighbor.append(document_matrix[i+4].toarray())\n",
        "\n",
        "  train_x.append(document_matrix[i+2].toarray())\n",
        "  train_y.append(neighbor)"
      ],
      "metadata": {
        "id": "3iaD6sY-BIAN"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_tensor = torch.FloatTensor(train_x).view(-1,document_matrix.shape[1]).to(device)\n",
        "train_y_tensor = torch.FloatTensor(train_y).view(4,-1,document_matrix.shape[1]).to(device)\n",
        "\n",
        "print(f'train_x의 shape : {train_x_tensor.shape}') # 단어 개수 * 4 * one_hot\n",
        "print(f'train_y의 shape : {train_y_tensor.shape}') # 단어 개수 * one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EXWqlK8BZ4G",
        "outputId": "8de9480f-64ce-422c-a510-b3bf3d12429c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 shape : torch.Size([46, 5])\n",
            "train_y의 shape : torch.Size([4, 46, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model"
      ],
      "metadata": {
        "id": "SCAxoau_BbjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "OYrMsaN9Bdkt"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weights without bias\n",
        "W = torch.randn(document_matrix.shape[1],emb_vector_size).to(device).requires_grad_()\n",
        "W_prime = torch.empty((4,emb_vector_size,document_matrix.shape[1])).to(device).requires_grad_()\n",
        "for w in W_prime:\n",
        "  w = torch.randn(emb_vector_size,document_matrix.shape[1])"
      ],
      "metadata": {
        "id": "mAnI75l7Bho9"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss\n",
        "SG_optimizer = optim.Adam([W], lr = lr)\n",
        "SG_optimizer_p = optim.Adam([W_prime], lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2XyQPj4FBo09"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 1 input vector\n",
        "  y_pred = train_x_tensor @ W\n",
        "  # Input : Embedding vector\n",
        "  # Output : predict 4 neighbor one-hot vector\n",
        "\n",
        "  W_prime = torch.transpose(W_prime,1,2)\n",
        "  y_pred = torch.transpose(y_pred,0,1)\n",
        "  y_pred = W_prime @ y_pred\n",
        "  y_pred = torch.transpose(y_pred,1,2)\n",
        "  W_prime = torch.transpose(W_prime,1,2)\n",
        "  y_pred = y_pred.softmax(dim = 2)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  SG_optimizer.zero_grad()\n",
        "  SG_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  SG_optimizer.step()\n",
        "  SG_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs5ao7foBqst",
        "outputId": "ef916a75-8ca4-4b6c-9d21-f62de8d91315"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 35.328975677490234\n",
            "epoch 500 : 35.363277435302734\n",
            "epoch 1000 : 35.2880859375\n",
            "epoch 1500 : 35.202186584472656\n",
            "epoch 2000 : 35.19779586791992\n",
            "epoch 2500 : 35.1953125\n",
            "epoch 3000 : 35.193721771240234\n",
            "epoch 3500 : 35.19257736206055\n",
            "epoch 4000 : 35.19169235229492\n",
            "epoch 4500 : 35.190956115722656\n",
            "epoch 5000 : 35.190303802490234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W)\n",
        "print(W_prime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA3mzqS3Bss9",
        "outputId": "66d99724-2eab-4007-9ded-27ba13598aa3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.4469,  1.8018],\n",
            "        [ 0.0357, -0.4149],\n",
            "        [-2.4160,  1.5630],\n",
            "        [ 1.5258, -3.8440],\n",
            "        [-2.5711, -2.6538]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.5897e+00, -1.8490e+00,  1.5906e+00, -1.8490e+00, -1.8490e+00],\n",
            "         [-1.3573e+00, -1.5676e+00,  1.3675e+00, -1.5676e+00, -1.5676e+00]],\n",
            "\n",
            "        [[ 1.5766e+00,  1.4848e+00, -2.4007e+00,  7.3007e-01, -1.7441e+00],\n",
            "         [-8.1129e-01, -2.0097e+00,  1.8158e+00,  7.7866e-01, -1.3027e+00]],\n",
            "\n",
            "        [[ 1.3365e+22,  9.9476e-01,  1.7740e+22, -9.9478e-01,  9.9476e-01],\n",
            "         [ 0.0000e+00, -1.2290e+00,  2.2421e-44,  1.2290e+00, -1.2290e+00]],\n",
            "\n",
            "        [[-5.2761e+05,  4.5916e-41,  7.9584e-01,  0.0000e+00, -7.9584e-01],\n",
            "         [ 2.7774e-02,  1.3417e+22, -3.3859e+00,  1.7702e+22,  3.3859e+00]]],\n",
            "       device='cuda:0', grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    }
  ]
}