{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castlechoi/studyingDL/blob/main/NLP/Word2Vec_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "-BBDyvlo64jq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-_ioJx6Iequ"
      },
      "source": [
        "## Download corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siYoaOebIarP",
        "outputId": "6c336d05-8bb0-4327-e9b1-a87e7ed715df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"book\", quiet = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsZGjVpZLHfR",
        "outputId": "d59524dc-c381-49d4-988b-fbea2d875247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# nltk.book에 저장된 다양한 corpus\n",
        "from nltk.book import *\n",
        "nltk.book.texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "2Zp4hBDdLRo4"
      },
      "outputs": [],
      "source": [
        "# tokenize 모두 완료 되어 있음\n",
        "ex_book = nltk.book.text1[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_PuXfZtJv5Z"
      },
      "source": [
        "## Stop-words 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjDC1GjqJ33J",
        "outputId": "6d50e75f-3375-4651-ea25-6374e43037df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop-words의 개수 : 198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# stop-words에 특수기호 추가\n",
        "stopwords  = stopwords + ['.',',','\\'','!','?','\\\"','[',']','(',')','*','I',':',';','-','.\"','--','<','>']\n",
        "\n",
        "print(f'Stop-words의 개수 : {len(stopwords)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9_pdV7KQ3aa",
        "outputId": "9fcbfdb4-e664-4bc2-c13e-71e57fe510e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제외한 후 문장의 길이 : 241\n"
          ]
        }
      ],
      "source": [
        "# 불용어 빠진 것을 확인\n",
        "ex_book_no_stopwords = [[t] for t in ex_book if t not in stopwords]\n",
        "print(f'불용어 제외한 후 문장의 길이 : {len(ex_book_no_stopwords)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing hyperparameter\n"
      ],
      "metadata": {
        "id": "MPW87KAt40kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_count = 2\n",
        "window = 2"
      ],
      "metadata": {
        "id": "yLBYPK0I43Wh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tBgafmjJp_a"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4mTUkbRqJr9B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ri8z-PZIDGYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632aa62a-75b1-4a97-a8d0-b7f6e2294f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token의 개수 : 24\n"
          ]
        }
      ],
      "source": [
        "# 토큰 집합 추출 ( 등장횟수가 2이하면 토큰화 안함)\n",
        "cut_off = 0\n",
        "\n",
        "tokens = pd.Series(ex_book_no_stopwords).value_counts()\n",
        "for i in range(len(tokens)):\n",
        "  if tokens[i] == min_count-1:\n",
        "    cut_off = i\n",
        "    break\n",
        "tokens = tokens[:cut_off].index.tolist()\n",
        "print(f'Token의 개수 : {len(tokens)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "a1jElU3oGhyk"
      },
      "outputs": [],
      "source": [
        "# token에 없는 데이터 모두 <unk>로 변경\n",
        "ex_book_process = [t if t in tokens else ['<unk>'] for t in ex_book_no_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUi_7NUSAgy",
        "outputId": "88a0ad98-fecd-4315-93e5-8f4584937dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서의 단의 개수 : 241\n",
            "One-Hot vector의 크기 : 25\n"
          ]
        }
      ],
      "source": [
        "# One-Hot Encoding\n",
        "oe = OneHotEncoder()\n",
        "document_matrix = oe.fit_transform(ex_book_process)\n",
        "print(f'문서의 단의 개수 : {document_matrix.shape[0]}')\n",
        "print(f'One-Hot vector의 크기 : {document_matrix.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2TBvGyeZByC"
      },
      "source": [
        "## GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-08pgoQjYqb",
        "outputId": "99b3e1ad-8403-45e7-c8eb-b1c169a19252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "#GPU 체크\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU is availalbe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Low-level"
      ],
      "metadata": {
        "id": "J9VnyFe37EY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train data preprocessing "
      ],
      "metadata": {
        "id": "ri8rts2u4ntK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "gM4OYUVSex_q"
      },
      "outputs": [],
      "source": [
        "# train_x에 CBOW의 input으로 들어가는 4개의 벡터\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(document_matrix.shape[0] - (window * 2)):\n",
        "  neighbor = []\n",
        "  neighbor.append(document_matrix[i].toarray())\n",
        "  neighbor.append(document_matrix[i+1].toarray())\n",
        "  neighbor.append(document_matrix[i+3].toarray())\n",
        "  neighbor.append(document_matrix[i+4].toarray())\n",
        "\n",
        "  train_x.append(neighbor)\n",
        "  train_y.append(document_matrix[i+2].toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alsm-k18kTIQ",
        "outputId": "bd618170-96aa-4cb3-effb-cada19349df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 shape : torch.Size([237, 4, 25])\n",
            "train_y의 shape : torch.Size([237, 25])\n"
          ]
        }
      ],
      "source": [
        "train_x_tensor = torch.FloatTensor(train_x).view(-1,4,document_matrix.shape[1]).to(device)\n",
        "train_y_tensor = torch.FloatTensor(train_y).view(-1,document_matrix.shape[1]).to(device)\n",
        "\n",
        "print(f'train_x의 shape : {train_x_tensor.shape}') # 단어 개수 * 4 * one_hot\n",
        "print(f'train_y의 shape : {train_y_tensor.shape}') # 단어 개수 * one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "d005sfmT4ezD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "FaHcjOM05PfC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "PAAl1iC9zk58"
      },
      "outputs": [],
      "source": [
        "# Define weights without bias\n",
        "W = torch.randn(document_matrix.shape[1],emb_vector_size).to(device).requires_grad_()\n",
        "W_prime = torch.randn(emb_vector_size,document_matrix.shape[1]).to(device).requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iitfzjLKUavm"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss\n",
        "CBOW_optimizer = optim.Adam([W], lr = lr)\n",
        "CBOW_optimizer_p = optim.Adam([W_prime], lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "1gATZ5t96fFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dThZmveFflDf",
        "outputId": "6b1b4575-3171-4436-d92f-40caa35922d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 3.1873133182525635\n",
            "epoch 500 : 2.735260009765625\n",
            "epoch 1000 : 2.549489974975586\n",
            "epoch 1500 : 2.532850742340088\n",
            "epoch 2000 : 2.5290212631225586\n",
            "epoch 2500 : 2.5275511741638184\n",
            "epoch 3000 : 2.5267441272735596\n",
            "epoch 3500 : 2.525071382522583\n",
            "epoch 4000 : 2.5167064666748047\n",
            "epoch 4500 : 2.512925624847412\n",
            "epoch 5000 : 2.5112602710723877\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = train_x_tensor @ W\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "  \n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = y_pred @ W_prime\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_optimizer.zero_grad()\n",
        "  CBOW_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_optimizer.step()\n",
        "  CBOW_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "gYGBTY2pxXJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BKCQjaIam_",
        "outputId": "6c39b3ca-d18b-42ef-b611-21f3d6f026cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5209, -0.5212],\n",
            "        [-2.2339,  1.9593],\n",
            "        [-1.0744,  2.1118],\n",
            "        [-2.8682,  0.6956],\n",
            "        [-2.9756,  0.4261],\n",
            "        [-0.9636,  2.1027],\n",
            "        [-2.3552,  0.7953],\n",
            "        [-1.8424,  0.4236],\n",
            "        [-3.3176,  1.3479],\n",
            "        [-4.3817, -2.1823],\n",
            "        [ 0.5047,  3.1857],\n",
            "        [-2.7700,  2.1188],\n",
            "        [-1.9593,  0.9386],\n",
            "        [-1.3785,  2.4849],\n",
            "        [ 4.1758,  0.4925],\n",
            "        [-1.2312,  2.9900],\n",
            "        [-1.5026,  2.3819],\n",
            "        [-0.4630,  1.3901],\n",
            "        [-0.7521,  2.9094],\n",
            "        [-3.8063,  0.5985],\n",
            "        [-1.8714,  4.0951],\n",
            "        [-2.5592,  0.3975],\n",
            "        [-1.3717, -0.0237],\n",
            "        [-0.9343,  0.8598],\n",
            "        [-1.1811,  0.2602]], device='cuda:0', requires_grad=True)\n",
            "tensor([[ 1.1965, -3.2145,  0.1024,  0.2095,  1.2201,  2.7619,  2.4853,  2.1779,\n",
            "          1.0853,  2.3532,  3.5925,  0.1972,  0.1986,  3.0633, -0.8037, -0.1925,\n",
            "         -0.8907,  0.3639,  1.3655,  2.8989, -0.2639,  1.1151,  0.8050,  1.8778,\n",
            "          1.1069],\n",
            "        [-1.2329,  1.3895, -3.7354, -2.3005, -1.1752, -2.5219, -1.5215, -0.8188,\n",
            "         -0.3493, -1.6127,  2.4273, -1.0865, -0.1273, -2.1708, -2.2343, -2.3492,\n",
            "         -1.7844, -1.2265, -1.9153, -2.3580, -0.4776, -1.7227, -0.7207, -1.8704,\n",
            "         -1.2561]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(W)\n",
        "print(W_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Using nn.Linear"
      ],
      "metadata": {
        "id": "yiMxNHhnlpsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "JbO4NMr_l3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "sYtNugRTlvve"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, optimizer and loss\n",
        "CBOW_linear = nn.Linear(document_matrix.shape[1], emb_vector_size, bias = False).to(device)\n",
        "CBOW_linear_p = nn.Linear(emb_vector_size,document_matrix.shape[1], bias = False).to(device)\n",
        "\n",
        "CBOW_linear_optimizer = optim.Adam(CBOW_linear.parameters(), lr = lr)\n",
        "CBOW_linear_optimizer_p = optim.Adam(CBOW_linear_p.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sycbLupbl7rK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "Ehj9RcufmTdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = CBOW_linear(train_x_tensor)\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "\n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = CBOW_linear_p(y_pred)\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "  \n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_linear_optimizer.zero_grad()\n",
        "  CBOW_linear_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_linear_optimizer.step()\n",
        "  CBOW_linear_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "id": "cxtqiW5UmS5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22987164-4c8a-40e7-ffc8-24464de94275"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 3.2166616916656494\n",
            "epoch 500 : 2.713001251220703\n",
            "epoch 1000 : 2.5400733947753906\n",
            "epoch 1500 : 2.530947208404541\n",
            "epoch 2000 : 2.5284221172332764\n",
            "epoch 2500 : 2.5273563861846924\n",
            "epoch 3000 : 2.526808738708496\n",
            "epoch 3500 : 2.5264925956726074\n",
            "epoch 4000 : 2.5262959003448486\n",
            "epoch 4500 : 2.526167154312134\n",
            "epoch 5000 : 2.5260801315307617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "ZeGURWuyxTZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emb in CBOW_linear.parameters():\n",
        "  print(emb)\n",
        "for emb in CBOW_linear_p.parameters():\n",
        "  print(emb)"
      ],
      "metadata": {
        "id": "21_ar2NKwf4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49f2f04-93cf-4fd6-c4c7-4671b1e64d83"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.3882, -1.5273, -1.3278, -1.4435, -1.3862, -1.5519, -1.5244, -1.5809,\n",
            "         -1.3239, -1.4496, -1.5288, -1.6652, -1.4898, -1.5440, -0.9196, -1.4412,\n",
            "         -1.5076, -1.5099, -1.6197, -1.6914, -1.7161, -1.4133, -1.6446, -1.6702,\n",
            "         -1.6066],\n",
            "        [ 1.6647,  1.7046,  1.7348,  1.5181,  1.7442,  1.4627,  1.5967,  1.7143,\n",
            "          1.1617,  1.7504,  1.4620,  1.4617,  1.6521,  1.5347,  0.8969,  1.7253,\n",
            "          1.4460,  1.4443,  1.5436,  1.6558,  1.4624,  1.5369,  1.4353,  1.5154,\n",
            "          1.4628]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.2102, -1.9989],\n",
            "        [-2.0631,  1.8450],\n",
            "        [ 1.5625, -1.4628],\n",
            "        [ 1.8891, -1.1678],\n",
            "        [ 1.8306, -1.8809],\n",
            "        [ 1.8420, -1.7414],\n",
            "        [ 1.9208, -1.7551],\n",
            "        [ 1.1312, -2.0279],\n",
            "        [ 1.7208, -1.0484],\n",
            "        [ 2.1885, -0.9130],\n",
            "        [ 2.2013, -0.9102],\n",
            "        [ 1.8098, -1.5049],\n",
            "        [ 1.4105, -1.2777],\n",
            "        [ 1.0903, -2.1824],\n",
            "        [ 1.6572, -1.6465],\n",
            "        [ 2.1013, -0.9333],\n",
            "        [ 1.9292, -1.4478],\n",
            "        [ 2.0453, -0.8819],\n",
            "        [ 1.6764, -1.3026],\n",
            "        [ 1.9055, -1.2654],\n",
            "        [ 0.9959, -1.8145],\n",
            "        [ 1.6867, -1.6762],\n",
            "        [ 1.6166, -1.3065],\n",
            "        [ 1.4380, -2.0745],\n",
            "        [ 1.6159, -1.2923]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-BBDyvlo64jq",
        "r-_ioJx6Iequ",
        "N2TBvGyeZByC",
        "J9VnyFe37EY5",
        "yiMxNHhnlpsP",
        "-n1NkZkZp4rK"
      ],
      "authorship_tag": "ABX9TyN4n3VcJMMVLz9O0Jf2/b6u",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}