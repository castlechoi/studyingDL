{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castlechoi/studyingDL/blob/main/NLP/Word2Vec_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "-BBDyvlo64jq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-_ioJx6Iequ"
      },
      "source": [
        "## Download corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siYoaOebIarP",
        "outputId": "045419b7-18d6-4b43-d2c7-c37c17e5ad09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"book\", quiet = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsZGjVpZLHfR",
        "outputId": "f5f2b4d8-611a-41f0-f3b3-095f4cb8c314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# nltk.book에 저장된 다양한 corpus\n",
        "from nltk.book import *\n",
        "nltk.book.texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2Zp4hBDdLRo4"
      },
      "outputs": [],
      "source": [
        "# tokenize 모두 완료 되어 있음\n",
        "ex_book = nltk.book.text1[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_PuXfZtJv5Z"
      },
      "source": [
        "## Stop-words 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjDC1GjqJ33J",
        "outputId": "d9e58805-1dac-4323-8c9d-8b9470cfd779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop-words의 개수 : 198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# stop-words에 특수기호 추가\n",
        "stopwords  = stopwords + ['.',',','\\'','!','?','\\\"','[',']','(',')','*','I',':',';','-','.\"','--','<','>']\n",
        "\n",
        "print(f'Stop-words의 개수 : {len(stopwords)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9_pdV7KQ3aa",
        "outputId": "69615997-8992-4fdc-cf92-5733a464cb36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제외한 후 문장의 길이 : 241\n"
          ]
        }
      ],
      "source": [
        "# 불용어 빠진 것을 확인\n",
        "ex_book_no_stopwords = [[t] for t in ex_book if t not in stopwords]\n",
        "print(f'불용어 제외한 후 문장의 길이 : {len(ex_book_no_stopwords)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing hyperparameter\n"
      ],
      "metadata": {
        "id": "MPW87KAt40kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_count = 2\n",
        "window = 2"
      ],
      "metadata": {
        "id": "yLBYPK0I43Wh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tBgafmjJp_a"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4mTUkbRqJr9B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ri8z-PZIDGYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27bf92ec-a150-42e6-d6a0-c904ebb6395d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token의 개수 : 24\n"
          ]
        }
      ],
      "source": [
        "# 토큰 집합 추출 ( 등장횟수가 2이하면 토큰화 안함)\n",
        "cut_off = 0\n",
        "\n",
        "tokens = pd.Series(ex_book_no_stopwords).value_counts()\n",
        "for i in range(len(tokens)):\n",
        "  if tokens[i] == min_count-1:\n",
        "    cut_off = i\n",
        "    break\n",
        "tokens = tokens[:cut_off].index.tolist()\n",
        "print(f'Token의 개수 : {len(tokens)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a1jElU3oGhyk"
      },
      "outputs": [],
      "source": [
        "# token에 없는 데이터 모두 <unk>로 변경\n",
        "ex_book_process = [t if t in tokens else ['<unk>'] for t in ex_book_no_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUi_7NUSAgy",
        "outputId": "d565079c-26a5-4e6e-daa4-f2aea5539277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서의 단의 개수 : 241\n",
            "One-Hot vector의 크기 : 25\n"
          ]
        }
      ],
      "source": [
        "# One-Hot Encoding\n",
        "oe = OneHotEncoder()\n",
        "document_matrix = oe.fit_transform(ex_book_process)\n",
        "print(f'문서의 단의 개수 : {document_matrix.shape[0]}')\n",
        "print(f'One-Hot vector의 크기 : {document_matrix.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2TBvGyeZByC"
      },
      "source": [
        "## GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-08pgoQjYqb",
        "outputId": "ee6eba06-b017-448a-d863-94889cde3918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "#GPU 체크\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU is availalbe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Low-level"
      ],
      "metadata": {
        "id": "J9VnyFe37EY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train data preprocessing "
      ],
      "metadata": {
        "id": "ri8rts2u4ntK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gM4OYUVSex_q"
      },
      "outputs": [],
      "source": [
        "# train_x에 CBOW의 input으로 들어가는 4개의 벡터\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(document_matrix.shape[0] - (window * 2)):\n",
        "  neighbor = []\n",
        "  neighbor.append(document_matrix[i].toarray())\n",
        "  neighbor.append(document_matrix[i+1].toarray())\n",
        "  neighbor.append(document_matrix[i+3].toarray())\n",
        "  neighbor.append(document_matrix[i+4].toarray())\n",
        "\n",
        "  train_x.append(neighbor)\n",
        "  train_y.append(document_matrix[i+2].toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alsm-k18kTIQ",
        "outputId": "d0e53bce-8f01-43db-d682-416985c1dae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-5119cb5fae7f>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  train_x_tensor = torch.FloatTensor(train_x).view(-1,4,document_matrix.shape[1]).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 shape : torch.Size([237, 4, 25])\n",
            "train_y의 shape : torch.Size([237, 25])\n"
          ]
        }
      ],
      "source": [
        "train_x_tensor = torch.FloatTensor(train_x).view(-1,4,document_matrix.shape[1]).to(device)\n",
        "train_y_tensor = torch.FloatTensor(train_y).view(-1,document_matrix.shape[1]).to(device)\n",
        "\n",
        "print(f'train_x의 shape : {train_x_tensor.shape}') # 단어 개수 * 4 * one_hot\n",
        "print(f'train_y의 shape : {train_y_tensor.shape}') # 단어 개수 * one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "d005sfmT4ezD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "FaHcjOM05PfC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PAAl1iC9zk58"
      },
      "outputs": [],
      "source": [
        "# Define weights without bias\n",
        "W = torch.randn(document_matrix.shape[1],emb_vector_size).to(device).requires_grad_()\n",
        "W_prime = torch.randn(emb_vector_size,document_matrix.shape[1]).to(device).requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iitfzjLKUavm"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss\n",
        "CBOW_optimizer = optim.Adam([W], lr = lr)\n",
        "CBOW_optimizer_p = optim.Adam([W_prime], lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "1gATZ5t96fFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dThZmveFflDf",
        "outputId": "616e01d9-7993-4312-8dae-d375945eb8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 3.2126963138580322\n",
            "epoch 500 : 2.796860456466675\n",
            "epoch 1000 : 2.5478672981262207\n",
            "epoch 1500 : 2.532090902328491\n",
            "epoch 2000 : 2.5286431312561035\n",
            "epoch 2500 : 2.527249574661255\n",
            "epoch 3000 : 2.5263795852661133\n",
            "epoch 3500 : 2.5256736278533936\n",
            "epoch 4000 : 2.5251193046569824\n",
            "epoch 4500 : 2.5246198177337646\n",
            "epoch 5000 : 2.5237510204315186\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = train_x_tensor @ W\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "  \n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = y_pred @ W_prime\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_optimizer.zero_grad()\n",
        "  CBOW_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_optimizer.step()\n",
        "  CBOW_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "gYGBTY2pxXJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BKCQjaIam_",
        "outputId": "9e2e63f7-41e6-4cb0-a789-23feb3dd8299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.3220,  1.4787],\n",
            "        [-2.4414,  1.7075],\n",
            "        [-2.3341,  0.9295],\n",
            "        [-1.1732,  2.3236],\n",
            "        [-1.2025,  2.1571],\n",
            "        [-0.9378,  2.3369],\n",
            "        [-2.5139,  2.1506],\n",
            "        [-2.9135,  0.4221],\n",
            "        [-1.7070,  1.9217],\n",
            "        [-2.0078,  2.4650],\n",
            "        [-1.3215, -0.2824],\n",
            "        [-1.7759,  1.2361],\n",
            "        [-1.5929,  2.0696],\n",
            "        [-3.2544,  1.7984],\n",
            "        [ 1.3931, -4.8613],\n",
            "        [ 0.5331,  2.3908],\n",
            "        [-1.8330,  2.5768],\n",
            "        [-0.4055,  0.9070],\n",
            "        [-2.1889,  1.1575],\n",
            "        [-3.0982,  3.2478],\n",
            "        [-2.6938,  3.3694],\n",
            "        [-1.4535,  2.2281],\n",
            "        [-1.0500,  0.6617],\n",
            "        [-1.4947,  1.4635],\n",
            "        [-3.1037,  1.7181]], device='cuda:0', requires_grad=True)\n",
            "tensor([[ 1.8155, -2.3166,  2.1170,  1.1251,  2.6273,  0.3144,  0.4515,  0.5457,\n",
            "          1.2717,  1.0745,  0.2162,  0.5289,  1.2387,  1.3951,  1.6938,  2.0017,\n",
            "          1.9484,  0.6135,  2.2504,  1.3866, -0.7047, -0.4065,  1.7640,  1.3886,\n",
            "          2.3144],\n",
            "        [-2.5776,  1.2235, -1.7368, -1.1090, -1.0648, -2.2194, -1.5345, -0.9398,\n",
            "         -2.1371, -1.0398, -1.2775, -2.9267,  0.0140, -1.2008, -2.1403, -1.2709,\n",
            "         -0.9442, -0.4809, -0.6002, -1.6539, -2.3532, -3.2100, -2.2815, -1.3994,\n",
            "         -0.9278]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(W)\n",
        "print(W_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Using nn.Linear"
      ],
      "metadata": {
        "id": "yiMxNHhnlpsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "JbO4NMr_l3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "sYtNugRTlvve"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, optimizer and loss\n",
        "CBOW_linear = nn.Linear(document_matrix.shape[1], emb_vector_size, bias = False).to(device)\n",
        "CBOW_linear_p = nn.Linear(emb_vector_size,document_matrix.shape[1], bias = False).to(device)\n",
        "\n",
        "CBOW_linear_optimizer = optim.Adam(CBOW_linear.parameters(), lr = lr)\n",
        "CBOW_linear_optimizer_p = optim.Adam(CBOW_linear_p.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sycbLupbl7rK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "Ehj9RcufmTdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = CBOW_linear(train_x_tensor)\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "\n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = CBOW_linear_p(y_pred)\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "  \n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_linear_optimizer.zero_grad()\n",
        "  CBOW_linear_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_linear_optimizer.step()\n",
        "  CBOW_linear_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "id": "cxtqiW5UmS5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22e50b3-57d0-4e43-bf31-0556586cca87"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 3.219789743423462\n",
            "epoch 500 : 2.796447992324829\n",
            "epoch 1000 : 2.540860891342163\n",
            "epoch 1500 : 2.5310275554656982\n",
            "epoch 2000 : 2.5284292697906494\n",
            "epoch 2500 : 2.527350425720215\n",
            "epoch 3000 : 2.5268001556396484\n",
            "epoch 3500 : 2.5264837741851807\n",
            "epoch 4000 : 2.526287317276001\n",
            "epoch 4500 : 2.5261573791503906\n",
            "epoch 5000 : 2.526066303253174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "ZeGURWuyxTZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emb in CBOW_linear.parameters():\n",
        "  print(emb)\n",
        "for emb in CBOW_linear_p.parameters():\n",
        "  print(emb)"
      ],
      "metadata": {
        "id": "21_ar2NKwf4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5b8721-2bc9-4243-e353-84861f278ba0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.6451,  1.5978,  1.4798,  1.7055,  1.4656,  1.4622,  1.4019,  1.4408,\n",
            "          1.4536,  1.6541,  1.4793,  1.6066,  1.7169,  1.4799, -0.3130,  1.6305,\n",
            "          1.3817,  1.4672,  1.5839,  1.5130,  1.6139,  1.4886,  1.5120,  1.5042,\n",
            "          1.4586],\n",
            "        [-1.6063, -1.4738, -1.6220, -1.4634, -1.5334, -1.6608, -1.7304, -1.6985,\n",
            "         -1.3077, -1.6038, -1.2266, -1.4555, -1.3957, -1.4720,  0.1532, -1.4922,\n",
            "         -1.6765, -1.6239, -1.3901, -1.6084, -1.7977, -1.5566, -1.6348, -1.5458,\n",
            "         -1.5837]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-1.9625,  1.9759],\n",
            "        [ 2.0504, -2.0034],\n",
            "        [-1.9161,  1.7455],\n",
            "        [-1.8670,  1.8951],\n",
            "        [-2.2532,  1.0594],\n",
            "        [-1.3523,  1.5523],\n",
            "        [-1.8164,  1.5042],\n",
            "        [-1.6907,  1.9174],\n",
            "        [-1.7495,  1.2905],\n",
            "        [-1.5355,  1.8914],\n",
            "        [-1.4297,  1.0106],\n",
            "        [-1.8764,  1.3475],\n",
            "        [-1.9775,  1.1070],\n",
            "        [-1.4960,  1.8240],\n",
            "        [-2.1098,  1.3480],\n",
            "        [-2.0008,  1.9029],\n",
            "        [-1.1953,  1.9662],\n",
            "        [-1.0982,  2.2125],\n",
            "        [-1.8861,  1.9101],\n",
            "        [-1.6528,  1.9891],\n",
            "        [-1.1178,  1.6731],\n",
            "        [-2.1879,  1.2611],\n",
            "        [-1.8235,  1.7248],\n",
            "        [-1.5992,  1.8056],\n",
            "        [-1.7068,  1.0137]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-BBDyvlo64jq",
        "r-_ioJx6Iequ",
        "N2TBvGyeZByC",
        "J9VnyFe37EY5",
        "yiMxNHhnlpsP",
        "-n1NkZkZp4rK"
      ],
      "authorship_tag": "ABX9TyN4n3VcJMMVLz9O0Jf2/b6u",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}