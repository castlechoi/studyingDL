{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castlechoi/studyingDL/blob/main/NLP/Word2Vec_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "-BBDyvlo64jq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-_ioJx6Iequ"
      },
      "source": [
        "## Download corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siYoaOebIarP",
        "outputId": "ae5d980e-b168-4986-9213-915f20fa02bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"book\", quiet = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsZGjVpZLHfR",
        "outputId": "895a202e-cc22-4c48-ee93-500e0337b62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# nltk.book에 저장된 다양한 corpus\n",
        "from nltk.book import *\n",
        "nltk.book.texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "2Zp4hBDdLRo4"
      },
      "outputs": [],
      "source": [
        "# tokenize 모두 완료 되어 있음\n",
        "ex_book = nltk.book.text1[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_PuXfZtJv5Z"
      },
      "source": [
        "## Stop-words 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjDC1GjqJ33J",
        "outputId": "8fc50553-b45f-48c6-f5f6-ac829461169e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop-words의 개수 : 198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# stop-words에 특수기호 추가\n",
        "stopwords  = stopwords + ['.',',','\\'','!','?','\\\"','[',']','(',')','*','I',':',';','-','.\"','--','<','>']\n",
        "\n",
        "print(f'Stop-words의 개수 : {len(stopwords)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9_pdV7KQ3aa",
        "outputId": "a1b7fc76-b150-4532-d8d2-a58328f35232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제외한 후 문장의 길이 : 50\n"
          ]
        }
      ],
      "source": [
        "# 불용어 빠진 것을 확인\n",
        "ex_book_no_stopwords = [[t] for t in ex_book if t not in stopwords]\n",
        "print(f'불용어 제외한 후 문장의 길이 : {len(ex_book_no_stopwords)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing hyperparameter\n"
      ],
      "metadata": {
        "id": "MPW87KAt40kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_count = 2\n",
        "window = 2"
      ],
      "metadata": {
        "id": "yLBYPK0I43Wh"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tBgafmjJp_a"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "4mTUkbRqJr9B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ri8z-PZIDGYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8a5534-6626-4b2c-a495-77f6a421dece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token의 개수 : 4\n"
          ]
        }
      ],
      "source": [
        "# 토큰 집합 추출 ( 등장횟수가 2이하면 토큰화 안함)\n",
        "cut_off = 0\n",
        "\n",
        "tokens = pd.Series(ex_book_no_stopwords).value_counts()\n",
        "for i in range(len(tokens)):\n",
        "  if tokens[i] == min_count-1:\n",
        "    cut_off = i\n",
        "    break\n",
        "tokens = tokens[:cut_off].index.tolist()\n",
        "print(f'Token의 개수 : {len(tokens)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "a1jElU3oGhyk"
      },
      "outputs": [],
      "source": [
        "# token에 없는 데이터 모두 <unk>로 변경\n",
        "ex_book_process = [t if t in tokens else ['<unk>'] for t in ex_book_no_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUi_7NUSAgy",
        "outputId": "e672fc89-3f3c-4cdb-eaf7-58fda90775e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서의 단의 개수 : 50\n",
            "One-Hot vector의 크기 : 5\n"
          ]
        }
      ],
      "source": [
        "# One-Hot Encoding\n",
        "oe = OneHotEncoder()\n",
        "document_matrix = oe.fit_transform(ex_book_process)\n",
        "print(f'문서의 단의 개수 : {document_matrix.shape[0]}')\n",
        "print(f'One-Hot vector의 크기 : {document_matrix.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2TBvGyeZByC"
      },
      "source": [
        "## GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-08pgoQjYqb",
        "outputId": "512d05f5-1631-47c5-a81f-0849482db193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "#GPU 체크\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU is availalbe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Low-level"
      ],
      "metadata": {
        "id": "J9VnyFe37EY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train data preprocessing "
      ],
      "metadata": {
        "id": "ri8rts2u4ntK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "gM4OYUVSex_q"
      },
      "outputs": [],
      "source": [
        "# train_x에 CBOW의 input으로 들어가는 4개의 벡터\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(document_matrix.shape[0] - (window * 2)):\n",
        "  neighbor = []\n",
        "  neighbor.append(document_matrix[i].toarray())\n",
        "  neighbor.append(document_matrix[i+1].toarray())\n",
        "  neighbor.append(document_matrix[i+3].toarray())\n",
        "  neighbor.append(document_matrix[i+4].toarray())\n",
        "\n",
        "  train_x.append(neighbor)\n",
        "  train_y.append(document_matrix[i+2].toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alsm-k18kTIQ",
        "outputId": "a0d01dd7-6422-4426-94dd-a23ef071b50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 shape : torch.Size([46, 4, 5])\n",
            "train_y의 shape : torch.Size([46, 5])\n"
          ]
        }
      ],
      "source": [
        "train_x_tensor = torch.FloatTensor(train_x).view(-1,4,document_matrix.shape[1]).to(device)\n",
        "train_y_tensor = torch.FloatTensor(train_y).view(-1,document_matrix.shape[1]).to(device)\n",
        "\n",
        "print(f'train_x의 shape : {train_x_tensor.shape}') # 단어 개수 * 4 * one_hot\n",
        "print(f'train_y의 shape : {train_y_tensor.shape}') # 단어 개수 * one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "d005sfmT4ezD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "FaHcjOM05PfC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "PAAl1iC9zk58"
      },
      "outputs": [],
      "source": [
        "# Define weights without bias\n",
        "W = torch.randn(document_matrix.shape[1],emb_vector_size).to(device).requires_grad_()\n",
        "W_prime = torch.randn(emb_vector_size,document_matrix.shape[1]).to(device).requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "iitfzjLKUavm"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss\n",
        "CBOW_optimizer = optim.Adam([W], lr = lr)\n",
        "CBOW_optimizer_p = optim.Adam([W_prime], lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "1gATZ5t96fFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dThZmveFflDf",
        "outputId": "7ddfaedc-1692-4ae9-c311-eb1ac9e9c32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 1.797547698020935\n",
            "epoch 500 : 1.617470145225525\n",
            "epoch 1000 : 1.1250122785568237\n",
            "epoch 1500 : 1.088291883468628\n",
            "epoch 2000 : 1.0827877521514893\n",
            "epoch 2500 : 1.0809146165847778\n",
            "epoch 3000 : 1.0800526142120361\n",
            "epoch 3500 : 1.0795886516571045\n",
            "epoch 4000 : 1.0793136358261108\n",
            "epoch 4500 : 1.0791399478912354\n",
            "epoch 5000 : 1.079025149345398\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = train_x_tensor @ W\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "  \n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = y_pred @ W_prime\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_optimizer.zero_grad()\n",
        "  CBOW_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_optimizer.step()\n",
        "  CBOW_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "gYGBTY2pxXJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BKCQjaIam_",
        "outputId": "a50d5f59-fe63-498f-e782-d81b5f71cc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.7064, -0.6959],\n",
            "        [ 1.2750, -1.2640],\n",
            "        [ 1.1298, -1.7958],\n",
            "        [ 0.9281, -1.0241],\n",
            "        [ 2.1942, -0.9534]], device='cuda:0', requires_grad=True)\n",
            "tensor([[ 2.2417, -2.6511, -0.9970, -0.2650, -2.0126],\n",
            "        [-2.1304, -0.4042,  2.6277,  3.2127,  0.7090]], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(W)\n",
        "print(W_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Using nn.Linear"
      ],
      "metadata": {
        "id": "yiMxNHhnlpsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "JbO4NMr_l3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 5000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "sYtNugRTlvve"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, optimizer and loss\n",
        "CBOW_linear = nn.Linear(document_matrix.shape[1], emb_vector_size, bias = False).to(device)\n",
        "CBOW_linear_p = nn.Linear(emb_vector_size,document_matrix.shape[1], bias = False).to(device)\n",
        "\n",
        "CBOW_linear_optimizer = optim.Adam(CBOW_linear.parameters(), lr = lr)\n",
        "CBOW_linear_optimizer_p = optim.Adam(CBOW_linear_p.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sycbLupbl7rK"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "Ehj9RcufmTdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = CBOW_linear(train_x_tensor)\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "\n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = CBOW_linear_p(y_pred)\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "  \n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_linear_optimizer.zero_grad()\n",
        "  CBOW_linear_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_linear_optimizer.step()\n",
        "  CBOW_linear_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "id": "cxtqiW5UmS5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d715f2c-b137-440a-a1dc-e1ba2a3f48e8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 1.6192408800125122\n",
            "epoch 500 : 1.2263877391815186\n",
            "epoch 1000 : 1.0951097011566162\n",
            "epoch 1500 : 1.0844076871871948\n",
            "epoch 2000 : 1.08151113986969\n",
            "epoch 2500 : 1.080324649810791\n",
            "epoch 3000 : 1.079729437828064\n",
            "epoch 3500 : 1.0793930292129517\n",
            "epoch 4000 : 1.0791875123977661\n",
            "epoch 4500 : 1.0790551900863647\n",
            "epoch 5000 : 1.078966498374939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print lookuptable"
      ],
      "metadata": {
        "id": "ZeGURWuyxTZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emb in CBOW_linear.parameters():\n",
        "  print(emb)\n",
        "for emb in CBOW_linear_p.parameters():\n",
        "  print(emb)"
      ],
      "metadata": {
        "id": "21_ar2NKwf4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9892abc7-0f7a-4598-8175-65693ff919b5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.6710, -1.4937, -1.3937, -1.7839, -1.9902],\n",
            "        [ 1.2332,  0.9611,  1.1870,  0.8982,  0.9458]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-1.0023,  2.1965],\n",
            "        [ 2.0194, -1.6008],\n",
            "        [ 1.9349, -1.6525],\n",
            "        [ 1.4033, -1.8451],\n",
            "        [ 1.4956, -1.9645]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-BBDyvlo64jq",
        "r-_ioJx6Iequ",
        "N2TBvGyeZByC",
        "J9VnyFe37EY5",
        "yiMxNHhnlpsP",
        "-n1NkZkZp4rK"
      ],
      "authorship_tag": "ABX9TyO4s02UrIf2Mk2UcHWMCvbR",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}