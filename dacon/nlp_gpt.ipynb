{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSURdjNq2o9WaSuyXwIdRw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDcTz6-arEjB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# load the data\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# preprocess the text data using CountVectorizer and convert the feature matrices to float64 type\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "train_feature = vectorizer.fit_transform(train_data['text']).astype(np.float64)\n",
        "train_label = train_data['label']\n",
        "test_feature = vectorizer.transform(test_data['text']).astype(np.float64)\n",
        "\n",
        "# split the data into training and validation sets\n",
        "val_size = 0.2\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_feature, train_label, test_size=val_size, random_state=42)\n",
        "\n",
        "# define the LightGBM model\n",
        "lgb_model = lgb.LGBMClassifier()\n",
        "\n",
        "# define the hyperparameter space to search\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'max_depth': [-1, 8, 16],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 500, 1000]\n",
        "}\n",
        "\n",
        "# define the evaluation metric\n",
        "eval_metric = 'f1_macro'\n",
        "\n",
        "# use GridSearchCV to search for the best hyperparameters based on F1 score\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring=eval_metric)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# train the model on the entire training set using the best hyperparameters\n",
        "best_lgb_model = lgb.LGBMClassifier(**grid_search.best_params_)\n",
        "best_lgb_model.fit(train_feature, train_label)\n",
        "\n",
        "# make predictions on the validation set\n",
        "y_val_pred = best_lgb_model.predict(X_val)\n",
        "\n",
        "# calculate the f1 score on the validation set\n",
        "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
        "print(\"F1 score on validation set:\", f1_macro)\n",
        "\n",
        "# make predictions on the test set\n",
        "y_test_pred = best_lgb_model.predict(test_feature)\n",
        "\n",
        "# save the predictions to a CSV file\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'label': y_test_pred})\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ]
    }
  ]
}