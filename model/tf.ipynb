{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL6FssRdaTAMxt8W7HHp7A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "7BWeBJlvLjI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./total_data.csv', encoding = 'cp949')\n",
        "df.head()\n",
        "df = df[df['종목명'] == 'KB금융']"
      ],
      "metadata": {
        "id": "NwjVHI2zLr0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_np = df['종가'].values\n",
        "print(len(df_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrYMIp2bMUWY",
        "outputId": "abc4b9a3-5103-47ef-ac4f-a6e6a1c15e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data split\n",
        "# input_dim = 50\n",
        "# forecast_dim = 3\n",
        "\n",
        "window_size = 50\n",
        "horizon_size = 3\n",
        "lr = 0.001\n",
        "num_epochs = 2000"
      ],
      "metadata": {
        "id": "HAZlN3hySAuJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "mm = MinMaxScaler()\n",
        "fitted = mm.fit(df_np.reshape(-1,1))\n",
        "out = mm.transform(df_np.reshape(-1,1))\n",
        "df_np = out.reshape(-1)\n",
        "for i in range(len(df_np) - window_size - horizon_size):\n",
        "  train_x.append(df_np[i:i+window_size]) # len == window_size\n",
        "  train_y.append(df_np[i+window_size: i+window_size + horizon_size]) # len == horizon_size\n",
        "\n",
        "x_tensor = torch.FloatTensor(train_x)\n",
        "y_tensor = torch.FloatTensor(train_y)\n",
        "print(f'src shape : {x_tensor.shape}')\n",
        "print(f'label shape : {y_tensor.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lddu-7DSuoH",
        "outputId": "71d24a67-70c3-4b24-8460-c430607f42ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src shape : torch.Size([934, 50])\n",
            "label shape : torch.Size([934, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,d_model, n_head, num_enc):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    # encoder layer parameter\n",
        "    self.d_model = d_model\n",
        "    self.n_head = n_head\n",
        "    self.num_enc = num_enc\n",
        "\n",
        "    self.encoderBlock = nn.TransformerEncoderLayer(\n",
        "      d_model = self.d_model,\n",
        "      nhead = self.n_head,\n",
        "      batch_first = True\n",
        "    )\n",
        "\n",
        "    self.encoder = nn.TransformerEncoder(\n",
        "        encoder_layer = self.encoderBlock,\n",
        "        num_layers = self.num_enc\n",
        "    )\n",
        "    \n",
        "    self.decoder = nn.Linear(d_model, d_model//2)\n",
        "    self.fc = nn.Linear(d_model//2, 3)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "      # encoder\n",
        "    out = self.encoder(x)\n",
        "      # encoder output == decoder input\n",
        "      # encoder output shape = encoder input shape\n",
        "\n",
        "      # decoder\n",
        "    out = self.decoder(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "      # forecast horizon which has a length of 3\n",
        "    return out"
      ],
      "metadata": {
        "id": "uHwcZV7mMkWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sMAPE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(sMAPE, self).__init__()\n",
        "  \n",
        "  def forward(self, src,tgt):\n",
        "    # src shape =  (700,1,3)\n",
        "    # tgt shape = (700,1,3)\n",
        "    tot = 0\n",
        "    s = src.view(-1,3)\n",
        "    t = tgt.view(-1,3)\n",
        "\n",
        "    up = torch.abs(s - t) # shape ( 700 , 3)\n",
        "    down =torch.abs(s) + torch.abs(t)\n",
        "\n",
        "    tot = torch.sum( up / down)\n",
        "    return 200 * tot / 3"
      ],
      "metadata": {
        "id": "fRmMuateaboN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "3lZ0aKnhWG_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = x_tensor.view(-1,1,window_size).to(device)\n",
        "y_tensor = y_tensor.view(-1,1,horizon_size).to(device)\n",
        "print(f'src shape : {x_tensor.shape}')\n",
        "print(f'label shape : {y_tensor.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMX6hMLNT8JH",
        "outputId": "29246d3c-5c6e-4b61-a1de-c01722834510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src shape : torch.Size([934, 1, 50])\n",
            "label shape : torch.Size([934, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model init\n",
        "model = Transformer(window_size,2,2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "criterion = sMAPE()"
      ],
      "metadata": {
        "id": "MS2uZbsOR_ZO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split\n",
        "train_x = x_tensor[:700]\n",
        "train_y = y_tensor[:700]\n",
        "test_x = x_tensor[700:]\n",
        "test_y = y_tensor[700:]"
      ],
      "metadata": {
        "id": "t2YLU_IkUscf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs+1):\n",
        "  optimizer.zero_grad()\n",
        "  pred = model(train_x)\n",
        "  loss = criterion(pred, train_y)\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch : {epoch} , Loss : {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBQrRairUjV3",
        "outputId": "fa6422d1-6e4e-4e80-943f-f81038e0564e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 , Loss : 134891.609375\n",
            "Epoch : 100 , Loss : 51858.82421875\n",
            "Epoch : 200 , Loss : 6823.18310546875\n",
            "Epoch : 300 , Loss : 5581.8740234375\n",
            "Epoch : 400 , Loss : 4735.8330078125\n",
            "Epoch : 500 , Loss : 4566.5869140625\n",
            "Epoch : 600 , Loss : 3713.9169921875\n",
            "Epoch : 700 , Loss : 4058.033203125\n",
            "Epoch : 800 , Loss : 3298.237060546875\n",
            "Epoch : 900 , Loss : 3268.35205078125\n",
            "Epoch : 1000 , Loss : 3040.9814453125\n",
            "Epoch : 1100 , Loss : 2817.36962890625\n",
            "Epoch : 1200 , Loss : 2706.423828125\n",
            "Epoch : 1300 , Loss : 2808.43896484375\n",
            "Epoch : 1400 , Loss : 2544.36962890625\n",
            "Epoch : 1500 , Loss : 2466.831787109375\n",
            "Epoch : 1600 , Loss : 2401.7685546875\n",
            "Epoch : 1700 , Loss : 2190.896484375\n",
            "Epoch : 1800 , Loss : 2355.681396484375\n",
            "Epoch : 1900 , Loss : 2133.4501953125\n",
            "Epoch : 2000 , Loss : 2102.663818359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(test_x)\n",
        "tot_loss = criterion(y_pred, test_y)\n",
        "print(f'Loss : {tot_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kFxk-q8W3Pd",
        "outputId": "11dee049-93a2-460e-f8d2-894bc6b8d177"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 2950.2622\n"
          ]
        }
      ]
    }
  ]
}