{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsF93OZzdB5gxyc5krmbXj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "r1hodmZ4nCq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0juyeHTanBPI"
      },
      "outputs": [],
      "source": [
        "# ResNet\n",
        "\"\"\"\n",
        "  skip-connection :\n",
        "    y = f(x) + x\n",
        "  \n",
        "  1x1 convolution의 역할 :\n",
        "    channel의 축소\n",
        "    ex ) 28 * 28 * 192  conv  1 * 1 * 16\n",
        "      => 28 * 28 * 16으로 데이터 줄이기 가능\n",
        "\n",
        "\"\"\"\n",
        "class ResidualNet(nn.Module):\n",
        "  def __init__(self, output_dim):\n",
        "    super(ResidualNet, self).__init__()\n",
        "\n",
        "    self.n_classes = output_dim\n",
        "    # 16, 1, 28, 28\n",
        "    self.conv1 = nn.Conv2d(1,8,kernel_size = 3, stride =1, padding = 1)\n",
        "    # 16, 128, 28, 28\n",
        "    self.block = nn.Sequential(\n",
        "        nn.Conv2d(8,4,kernel_size = 1,stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(4,4, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(4,8, kernel_size = 1, stride = 1),\n",
        "    )\n",
        "\n",
        "    self.softmax = nn.Softmax(dim = -1)\n",
        "    self.fc = nn.Linear(8* 28 * 28,self.n_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    identity = x\n",
        "    out = self.block(x)\n",
        "    out += identity\n",
        "    #flatten\n",
        "    out = out.view(x.size(0),-1)\n",
        "    out = self.softmax(out)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dl = torchvision.datasets.QMNIST('./',download = True,\n",
        "                                          transform = transforms.ToTensor())\n",
        "idx = np.arange(0,6000,2)\n",
        "mnist = Subset(mnist_dl,idx)\n",
        "data_loader = torch.utils.data.DataLoader(mnist_dl,\n",
        "                                          batch_size = 64,\n",
        "                                          shuffle = True\n",
        "                                          )"
      ],
      "metadata": {
        "id": "88hehwyElbtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(mnist)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "valid_size = int(dataset_size * 0.1)\n",
        "test_size = dataset_size - train_size - valid_size\n",
        "train_dl, valid_dl, test_dl = random_split(mnist,[train_size, valid_size, test_size])\n",
        "\n",
        "print(f'train data size : {len(train_dl)}')\n",
        "print(f'valid data size : {len(valid_dl)}')\n",
        "print(f'test data size : {len(test_dl)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYfeep7vmdnl",
        "outputId": "c14ca619-1ab2-468c-cf37-d39dd781dc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data size : 2400\n",
            "valid data size : 300\n",
            "test data size : 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dl, batch_size = 16, shuffle = True, drop_last = True)\n",
        "valid_loader = DataLoader(valid_dl, batch_size = 16, shuffle = True, drop_last = True)\n",
        "test_loader = DataLoader(test_dl, batch_size = 16, shuffle = True, drop_last = True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "okXhG1UlnOkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResidualNet(10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "ohXu7IFAnem7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "for epoch in range(30):\n",
        "  cost = 0\n",
        "  for x, y in train_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    pred = model(x)\n",
        "    loss = criterion(pred,y)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "  \n",
        "  cost = cost / len(train_loader)\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch {epoch} : {cost}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  cost = 0\n",
        "  for x,y in valid_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    pred = model(x)\n",
        "    prediction = torch.argmax(pred,1) == y\n",
        "\n",
        "    loss = prediction.float().mean()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost /= len(valid_loader)\n",
        "  print(f\"Acc : {cost * 100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sABMeN1soRjM",
        "outputId": "c4f9ace1-edb9-4b79-c0ca-4e1ee619fae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 0.017216073349118233\n",
            "Epoch 10 : 0.007503797300159931\n",
            "Epoch 20 : 0.003453581128269434\n",
            "Acc : 100.0\n"
          ]
        }
      ]
    }
  ]
}